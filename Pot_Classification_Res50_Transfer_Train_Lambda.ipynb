{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Y1IM42J0jpAK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (0.16.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (1.34.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (68.2.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from wandb) (4.25.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/christian/anaconda3/envs/ML/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "559zkuP5W6FB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 10:54:35.665325: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-05 10:54:35.710244: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-05 10:54:35.849587: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-05 10:54:35.849614: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-05 10:54:35.850632: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-05 10:54:35.925024: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-05 10:54:35.926285: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-05 10:54:36.743136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\" #This prevents Wandb from logging. Comment it out to re enable.\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rHGp4dUAANe9"
   },
   "outputs": [],
   "source": [
    "import datetime, os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUmU3Z76fieA"
   },
   "source": [
    "## Parameter Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "er4NfWHx6_4k"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'Resnet50-P'\n",
    "PROJECT_NAME = 'Road-Deformations'\n",
    "RUN_ID = \"ResNetP-2\"\n",
    "seed = 10\n",
    "image_width = 1920\n",
    "image_height = 1090\n",
    "im_shape = (image_width, image_height)\n",
    "continue_previous_training = False # True: load in model to resume training\n",
    "MODEL_SAVE_DIR = './models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5orVrNYLfTmT"
   },
   "outputs": [],
   "source": [
    "data_is_zipped = True #If you upload your data in zip files, this will unzip them for you.\n",
    "DATA_DIR = '/home/christian/Desktop/Creates/CREATEs Rework/Rework V2/Dataset'\n",
    "LABELED_DATA = False #Data from directory if false. This actually does nothing rn. Will implement later.\n",
    "labels_path = './pothole_labels.txt'#Also does nothing rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jUw_LEEq-B56"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 10:54:42.096463: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 3\n",
    "LEARNING_RATE = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_BACKUP = DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Igd_5G1Tfd1H"
   },
   "source": [
    "## Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HdcKCbGkmsec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    entity=\"hechtc87\",\n",
    "    config={\n",
    "        \"name\": MODEL_NAME,\n",
    "        \"id\": RUN_ID,\n",
    "        \"output_activation\": \"softmax\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss\": \"categorical_crossentropy\",\n",
    "        \"metric\": [\"accuracy\", \"precision\", \"recall\"],\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"image_width\": image_width,\n",
    "        \"image_height\": image_height,\n",
    "        \"num_log_batches\": 15,\n",
    "        \"lr\":LEARNING_RATE,\n",
    "        'seed': seed\n",
    "      }\n",
    ")\n",
    "\n",
    "\n",
    "tf.random.set_seed(wandb.config.seed)\n",
    "np.random.seed(wandb.config.seed)\n",
    "random.seed(wandb.config.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(wandb.config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zb-mByYdsy6"
   },
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NP-BVM9TcDUc"
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "        validation_split=0.2,\n",
    "        # width_shift_range=0.2,\n",
    "        # height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        # shear_range=0.2,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=20,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip Folders\n",
    "Run the below code if the data is uploaded in zipped folders\n",
    "TODO: Right now the code will throw an error if anything other than zip files are in the dataset directory. Make it so that this does not happen. Should the code simply ignore other files or tell the user? Idk yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "F615xjLV-JrL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data folder already exists. Skipping this process.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from zipfile import ZipFile\n",
    "unzipped_folder_name = 'Extracted_Data'\n",
    "if DATA_DIR.find(unzipped_folder_name) != -1: #This fixes a directory error if this cell is run multiple times\n",
    "    DATA_DIR = DATA_DIR_BACKUP\n",
    "\n",
    "\n",
    "filenames = listdir(DATA_DIR)\n",
    "\n",
    "if unzipped_folder_name in filenames:\n",
    "    print(\"Extracted Data folder already exists. Skipping this process.\")\n",
    "else:\n",
    "    if data_is_zipped:\n",
    "        for f in filenames:\n",
    "            path_to_zip = f'{DATA_DIR}/{f}'\n",
    "            path_to_downloaded_file = tf.keras.utils.get_file(\n",
    "              f'{DATA_DIR}/{f}',\n",
    "              'file://'+path_to_zip,\n",
    "              extract=True)\n",
    "            \n",
    "            directory_to_extract_to = DATA_DIR+'/'+unzipped_folder_name+'/'+f[:-3]\n",
    "            with ZipFile(path_to_zip, 'r') as zip_ref:\n",
    "                zip_ref.extractall(directory_to_extract_to)\n",
    "                \n",
    "if DATA_DIR.find(unzipped_folder_name) == -1:\n",
    "    DATA_DIR = DATA_DIR + '/' + unzipped_folder_name #changes data dir to extraction location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_32O-vUBKtD"
   },
   "source": [
    "## Merge Subfolders into 'Data'\n",
    "Usually it is easiest to break a dataset into multiple zip files to upload it. The below code will merge the extracted data into a single folder.\n",
    "\n",
    "#### _YOU NEED LABELS IN ORDER TO DO THIS_\n",
    "Do not run this if your data is uploaded with each class in a single zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q1oGeDrP-NUt",
    "outputId": "ef343e2d-ae05-4470-bd7d-92b460fbc79d"
   },
   "outputs": [],
   "source": [
    "if LABELED_DATA == True:\n",
    "    from functions import merge_subfolders\n",
    "    source_folder = DATA_DIR + '/' + unzipped_folder_name\n",
    "    destination_folder = DATA_DIR + '/merged_dataset'\n",
    "    \n",
    "    merge_subfolders(source_folder, destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Directory from Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nkfpojPjKuSK"
   },
   "outputs": [],
   "source": [
    "if LABELED_DATA == True:\n",
    "    import shutil\n",
    "    \n",
    "    def extract_base_filename(file_entry):\n",
    "        return file_entry.split(',')[0]\n",
    "    \n",
    "    def move_files_to_folders(file_list):\n",
    "        for file_entry in file_list:\n",
    "            filename, folder_num = file_entry.split(',')\n",
    "            folder_num = folder_num.strip()\n",
    "            folder_path = os.path.join(\"./Data\", str(folder_num))\n",
    "    \n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "    \n",
    "            src_path = os.path.join(\"./Data_2\", filename)\n",
    "            dst_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "              shutil.move(src_path, dst_path)\n",
    "              print(f\"Moved {filename} to {folder_path}\")\n",
    "            except:\n",
    "              print(\"Img not found\")\n",
    "    \n",
    "    with open(labels_path, \"r\") as f:\n",
    "        file_list = f.readlines()\n",
    "    \n",
    "    move_files_to_folders(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jYyYyzbkQP_s"
   },
   "outputs": [],
   "source": [
    "#!rm -rf ./Data/.ipynb_checkpoints #deletes checkpoint artifact from dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/christian/Desktop/Creates/CREATEs Rework/Rework V2/Dataset/Extracted_Data\n"
     ]
    }
   ],
   "source": [
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "kClLvothcBU4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 583 images belonging to 2 classes.\n",
      "Found 145 images belonging to 2 classes.\n",
      "Classes: ['0', '1']\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(DATA_DIR, target_size=im_shape, shuffle=True, seed=seed,\n",
    "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n",
    "validation_generator = data_generator.flow_from_directory(DATA_DIR, target_size=im_shape, shuffle=False, seed=seed,\n",
    "                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n",
    "\n",
    "\n",
    "nb_train_samples = train_generator.samples\n",
    "nb_validation_samples = validation_generator.samples\n",
    "classes = list(train_generator.class_indices.keys())\n",
    "print('Classes: '+str(classes))\n",
    "num_classes  = len(classes)\n",
    "\n",
    "test_data_list = []\n",
    "test_labels_list = []\n",
    "\n",
    "for i in range(len(validation_generator)):\n",
    "    data_batch, labels_batch = validation_generator[i]\n",
    "    test_data_list.append(data_batch)\n",
    "    test_labels_list.append(labels_batch)\n",
    "\n",
    "test_data = np.vstack(test_data_list)\n",
    "test_labels = np.vstack(test_labels_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "YUy76AWxGw7K"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(train_generator.classes)\n",
    "max_val = float(max(counter.values()))\n",
    "class_weights = {class_id : nb_train_samples/(num_images * num_classes) for class_id, num_images in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "I0GAL4w1iUa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch 194\n",
      "Validation Steps 48\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = nb_train_samples // BATCH_SIZE\n",
    "validation_steps = nb_validation_samples // BATCH_SIZE\n",
    "print(\"Steps per epoch\", steps_per_epoch)\n",
    "print(\"Validation Steps\", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-hf-GT4Qegu",
    "outputId": "6fb566c6-7ecf-453a-895a-83b11b2ce376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.9024767801857585, 1: 1.1211538461538462}\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NusVjclQ9rUo"
   },
   "source": [
    "# Create New Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "VLQu4XhNa3Va"
   },
   "outputs": [],
   "source": [
    "if continue_previous_training == False:\n",
    "  transfer_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_width,image_height,3))\n",
    "  for l in transfer_model.layers:\n",
    "    l.trainable = False\n",
    "\n",
    "  #Add new layers to tail of model\n",
    "  model = transfer_model.output\n",
    "  model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "  model = tf.keras.layers.Dense(128, activation='relu')(model)\n",
    "  model = tf.keras.layers.Dropout(rate=0.2)(model)\n",
    "  model = tf.keras.layers.Dense(128, activation='relu')(model)\n",
    "  model = tf.keras.layers.Dropout(rate=0.2)(model)\n",
    "  model = tf.keras.layers.Dense(num_classes, activation='softmax')(model)\n",
    "  model = tf.keras.models.Model(inputs = transfer_model.input, outputs = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5q59s9c9u3n"
   },
   "source": [
    "Or Load old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "dm83u62R99yH"
   },
   "outputs": [],
   "source": [
    "if continue_previous_training == True:\n",
    "  model = keras.models.load_model(f\"{MODEL_SAVE_DIR}/models/{MODEL_NAME}_last_10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "lcOA_TAMbCV2"
   },
   "outputs": [],
   "source": [
    "show_summary = False\n",
    "if show_summary:\n",
    "  model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HmqKMU1deAIN"
   },
   "outputs": [],
   "source": [
    "precision_metrics = tf.keras.metrics.Precision(name=\"precision\")\n",
    "recall_metrics = tf.keras.metrics.Recall(name=\"recall\")\n",
    "accuracy_metrics = tf.keras.metrics.CategoricalAccuracy(name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bLhLkQ3CbLTO"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=wandb.config.loss,optimizer = optimizer, metrics= [accuracy_metrics, precision_metrics, recall_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redo this cell \\/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "a86fUNJgbN1J"
   },
   "outputs": [],
   "source": [
    "filepath = \"/saved-model-{epoch:02d}-{val_accuracy:.2f}\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(MODEL_SAVE_DIR+MODEL_NAME+ filepath , monitor=\"val_accuracy\",save_best_only=False, mode=\"auto\", verbose=0)\n",
    "checkpoint2 = ModelCheckpoint(MODEL_SAVE_DIR+MODEL_NAME+filepath , monitor=\"val_accuracy\",save_best_only=True, mode=\"auto\", verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "                              mode='auto',verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2be23HQOy_z2"
   },
   "outputs": [],
   "source": [
    "class PRMetrics(Callback):\n",
    "  \"\"\" Custom callback to compute metrics at the end of each training epoch\"\"\"\n",
    "  def __init__(self, generator=None, num_log_batches=1):\n",
    "    self.generator = generator\n",
    "    self.num_batches = num_log_batches\n",
    "    # store full names of classes\n",
    "    self.flat_class_names = [k for k, v in generator.class_indices.items()]\n",
    "\n",
    "  def on_train_end(self, logs={}):\n",
    "    # collect validation data and ground truth labels from generator\n",
    "    val_data, val_labels = zip(*(self.generator[i] for i in range(self.num_batches)))\n",
    "    val_data, val_labels = np.vstack(val_data), np.vstack(val_labels)\n",
    "    # Load the best checkpoint model\n",
    "    model.load_weights(MODEL_SAVE_DIR+'/models/60_Epochs_Experiments/'+MODEL_NAME+ '/best_val_acc_model.h5')\n",
    "    # use the trained model to generate predictions for the given number\n",
    "    # of validation data batches (num_batches)\n",
    "    val_predictions = self.model.predict(val_data)\n",
    "    ground_truth_class_ids = val_labels.argmax(axis=1)\n",
    "    # take the argmax for each set of prediction scores\n",
    "    # to return the class id of the highest confidence prediction\n",
    "    top_pred_ids = val_predictions.argmax(axis=1)\n",
    "\n",
    "    # Log confusion matrix\n",
    "    # the key \"conf_mat\" is the id of the plot--do not change\n",
    "    # this if you want subsequent runs to show up on the same plot\n",
    "    wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=None,\n",
    "                            preds=top_pred_ids, y_true=ground_truth_class_ids,\n",
    "                            class_names=self.flat_class_names)})\n",
    "    wandb.log({\"roc_curve\" : wandb.plot.roc_curve(ground_truth_class_ids, val_predictions, labels=self.flat_class_names)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5k8kD8ijFE3"
   },
   "source": [
    "GradCam Callback\n",
    "Ref: https://www.kaggle.com/ayuraj/gradcam-implementation-visualization-in-tf-w-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Mn0LWHbdmqX9"
   },
   "outputs": [],
   "source": [
    "class UnfreezeCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, unfreeze_epoch):\n",
    "        super(UnfreezeCallback, self).__init__()\n",
    "        self.unfreeze_epoch = unfreeze_epoch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch == self.unfreeze_epoch:\n",
    "            print(\"Unfreezing the whole model...\")\n",
    "            model = self.model\n",
    "            for layer in model.layers:\n",
    "                layer.trainable = True\n",
    "            model.compile(loss=wandb.config.loss, optimizer = optimizer, metrics= [accuracy_metrics, precision_metrics, recall_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PGGkVoSOgEBC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "callbacks = [\n",
    "    WandbCallback(input_type='image', training_data=train_generator),\n",
    "    checkpoint2\n",
    "    \n",
    "    # tensorboard,\n",
    "    #UnfreezeCallback(10), #May be causing issues\n",
    "    #PRMetrics(validation_generator, wandb.config.num_log_batches),\n",
    "    # GRADCamLogger(test_generator, layer_name='stem_conv1'),\n",
    "    # checkpoint,\n",
    "    # reduce_lr,\n",
    "    # early_stopping,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrS10p5kbRBr",
    "outputId": "084383db-4e8d-4e43-9ad2-2a9061fe2a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "194/194 [==============================] - ETA: 0s - loss: 1.7725 - accuracy: 0.6207 - precision: 0.6207 - recall: 0.6207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m No validation_data set, pass a generator to the callback.\n",
      "/home/christian/anaconda3/envs/ML/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/christian/Desktop/Creates/CREATEs Rework/Rework V2/wandb/offline-run-20240305_105442-asoxpy1a/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/christian/Desktop/Creates/CREATEs Rework/Rework V2/wandb/offline-run-20240305_105442-asoxpy1a/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/christian/Desktop/Creates/CREATEs Rework/Rework V2/wandb/offline-run-20240305_105442-asoxpy1a/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55556, saving model to ./models/Resnet50-P/saved-model-01-0.56\n",
      "INFO:tensorflow:Assets written to: ./models/Resnet50-P/saved-model-01-0.56/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/Resnet50-P/saved-model-01-0.56/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 1376s 7s/step - loss: 1.7725 - accuracy: 0.6207 - precision: 0.6207 - recall: 0.6207 - val_loss: 0.6872 - val_accuracy: 0.5556 - val_precision: 0.5556 - val_recall: 0.5556\n",
      "Epoch 2/2\n",
      " 12/194 [>.............................] - ETA: 20:23 - loss: 0.7226 - accuracy: 0.4706 - precision: 0.4706 - recall: 0.4706"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    callbacks=callbacks,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = validation_generator,\n",
    "    verbose = 1,\n",
    "    validation_steps = validation_steps,\n",
    "    class_weight=class_weights\n",
    "  )\n",
    "#pass a generator to the wandb callback\n",
    "#Find a way to save the model as a savedmodel instead of an h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXwFYUyDhqYn"
   },
   "outputs": [],
   "source": [
    "#save the last model\n",
    "model_save = False\n",
    "if model_save == True:\n",
    "    model.save(f'{MODEL_SAVE_DIR}{MODEL_NAME}_{EPOCHS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "Nd9eTTb0bqf1",
    "outputId": "538754e8-b266-45e8-9769-a2ae3d0cafc0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting import *\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDNiKoC2AXa1"
   },
   "outputs": [],
   "source": [
    "# Extracting False Negatives\n",
    "def evaluate_model(model, data, labels):\n",
    "  false_predictions = []\n",
    "  count = 0\n",
    "  for img, label in zip(data, labels):\n",
    "    image = image = tf.expand_dims(img, axis=0)\n",
    "    predicted = model.predict(image)\n",
    "    true_label= np.argmax(label)\n",
    "    predicted_label = np.argmax(predicted)\n",
    "    confidence = predicted[0][predicted_label]\n",
    "    count +=1\n",
    "\n",
    "    if count%20==0:\n",
    "      false_predictions.append([img, true_label, predicted_label, confidence, predicted])\n",
    "  return false_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VcoHZQTAYkG"
   },
   "outputs": [],
   "source": [
    "def sove_plots(false_predictions, model, last_conv_layer_name):\n",
    "  for i, sample in enumerate(false_predictions):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(20, 10))\n",
    "    plt.subplots_adjust(bottom=0)\n",
    "    img, true_label, predicted_label, trust, prediction = sample[0], sample[1], sample[2], sample[3], sample[4][0]\n",
    "\n",
    "    im_class = classes[true_label]\n",
    "    true_label_class = r\"True Label: $\\bf{\" + str(classes[true_label]) + \"}$\"\n",
    "    predicted_label_class = r\"Predicted Label: $\\it{\"+ str(classes[predicted_label]) + \"}$\"\n",
    "\n",
    "    confidence = \"Confidence: \" + str(trust)\n",
    "\n",
    "    img_array = get_img_array(img)\n",
    "    # Remove last layer's softmax\n",
    "    model.layers[-1].activation = None\n",
    "    # Print what the top predicted class is\n",
    "    preds = model.predict(img_array)\n",
    "    title = \"{} \\n {} \\n {} \\n\".format(\n",
    "        true_label_class, predicted_label_class, confidence)\n",
    "    plt.axis('off')\n",
    "    heatmap = gradcam_heatmap(img_array, model, last_layer_name)\n",
    "    heatmap = np.reshape(heatmap, (7,7))\n",
    "    display_gradcam(img, heatmap, preds=preds[0], plot=ax1)\n",
    "    _ = ax2.imshow(img)\n",
    "    _ = ax3.imshow(heatmap)\n",
    "    ax1.set_title(\"GradCam\")\n",
    "    ax2.set_title(title)\n",
    "    ax3.set_title('Attention Map')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print('------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "import importlib\n",
    "importlib.reload(plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBW6mqRwAOiW"
   },
   "outputs": [],
   "source": [
    "plotting.plot_history_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lLcsdN3r_tpu"
   },
   "outputs": [],
   "source": [
    "plot_history_precision_recall(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZfytEImbYqt"
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (12, 12), fontsize=14):\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    confusion_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         confusion_matrix.flatten() / np.sum(confusion_matrix)]\n",
    "\n",
    "    labels = [f\"{v2}\\n{v3}\" for v2, v3 in\n",
    "              zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(len(class_names), len(class_names))\n",
    "\n",
    "\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names,\n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=labels, fmt='', cmap='Blues')\n",
    "\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # Note that due to returning the created figure object, when this funciton is called in a notebook\n",
    "    # the figure willl be printed twice. To prevent this, either append ; to your function call, or\n",
    "    # modify the function by commenting out this return expression.\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAjAYgYO_yy3"
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_data)\n",
    "ground_truth_class_ids = test_labels.argmax(axis=1)\n",
    "\n",
    "# take the argmax for each set of prediction scores\n",
    "# to return the class id of the highest confidence prediction\n",
    "top_pred_ids = test_predictions.argmax(axis=1)\n",
    "conf_mat = confusion_matrix(ground_truth_class_ids, top_pred_ids)\n",
    "figure = print_confusion_matrix(conf_mat, classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeeXKdg2_1oV"
   },
   "outputs": [],
   "source": [
    "predictions = evaluate_model(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kw8DifXt_7T0"
   },
   "outputs": [],
   "source": [
    "last_layer_name = 'conv5_block3_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSncpwx7_8s1"
   },
   "outputs": [],
   "source": [
    "sove_plots(predictions, model, last_layer_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
